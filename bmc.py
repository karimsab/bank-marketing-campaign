import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
import streamlit as st


st.title('Analyse des campagnes promotionnelles bancaires')
st.caption('par Karim SABER-CHERIF et Artem VALIULIN')

df = pd.read_csv("https://raw.githubusercontent.com/karimsab/bank-marketing-campaign/main/bank.csv", sep=",", header=0)

#####################################################################################
#####################################################################################

df_new = df.copy() # On enregistre df dans df_new pour ne pas corrompre les donn√©es de df
df_new.deposit = df_new.deposit.replace(['no', 'yes'], [0, 1])
df_new = df_new.drop(['duration'], axis=1)
data = df_new.drop('deposit', axis=1)
target = df_new['deposit']
df_new['campaign'] = df_new['campaign'].apply(lambda x : df_new.campaign.mean() if x > 35 else x)

# On remplace les variables binaires par 0 ou 1
data.housing = data.housing.replace(['no', 'yes'], [0, 1])
data.loan = data.loan.replace(['no', 'yes'], [0, 1])
data.default = data.default.replace(['no', 'yes'], [0, 1])
data = data.join(pd.get_dummies(data.marital, prefix='marital'))
data = data.join(pd.get_dummies(data.job, prefix='job'))
data = data.join(pd.get_dummies(data.contact, prefix='contact'))
data = data.join(pd.get_dummies(data.month, prefix='month'))
data = data.join(pd.get_dummies(data.poutcome, prefix='pout'))
data = data.join(pd.get_dummies(data.education, prefix='edu'))

data = data.drop(['marital', 'job', 'contact', 'month', 'poutcome', 'education'], axis=1)

# TEST DES MODELES
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.model_selection import train_test_split

# on split nos donn√©es
X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25)

# On cr√©e 6 instances √† partir de 6 mod√®les de classifieurs diff√©rents
gbc = GradientBoostingClassifier()
lr = LogisticRegression()
dt = DecisionTreeClassifier()
rf = RandomForestClassifier()
ac = AdaBoostClassifier()
bc = BaggingClassifier()

# On entraine les mod√®les sur les donn√©es d'entrainement
gbc.fit(X_train, y_train)
lr.fit(X_train, y_train)
dt.fit(X_train, y_train)
rf.fit(X_train, y_train)
ac.fit(X_train, y_train)
bc.fit(X_train, y_train)

from sklearn.model_selection import cross_val_score
# On pr√©dit
y_pred_gbc = gbc.predict(X_test)
y_pred_dt = dt.predict(X_test)

#####################################################################################
#####################################################################################

page = st.sidebar.selectbox("Menu", ["Etude des variables", "Tests statistiques", "Machine learning"]) 

###### affichage des diff√©rentes pages ######
###### page √©tudes des variables ######

if page == "Etude des variables":   

    st.image('https://user-images.githubusercontent.com/62601686/165300401-3f1257db-3a61-419a-bf7a-840c3c013ff7.png', width=800)
    st.text("Pour ce jeu de donn√©es, nous avons des donn√©es personnelles sur des clients \n\
d‚Äôune banque qui ont √©t√© ‚Äút√©l√©market√©s‚Äù pour souscrire √† un produit que \n\
l‚Äôon appelle un 'd√©p√¥t √† terme'. Lorsqu‚Äôun client souscrit √† ce produit, il place \n\
une quantit√© d‚Äôargent dans un compte sp√©cifique et ne pourra pas toucher ces fonds \n\
avant l‚Äôexpiration du terme. En √©change, le client re√ßoit des int√©r√™ts de la \n\
part de la banque √† la fin du terme.")
    st.markdown('Le jeu de donn√©es initial :')
    st.dataframe(df)
    st.markdown('Explication des variables :')
    st.text("1 - age : √¢ge du client \n\
2 - job : m√©tier du client \n\
3 - marital : statut marital du client \n\
4 - education : niveau d'√©tude du client \n\
5 - default : si le client √† un cr√©dit impay√© \n\
6 - balance : somme d'argent sur le compte bancaire \n\
7 - housing : si le client a un empr√ªnt immobilier \n\
8 - loan : si le client √† un cr√©dit en cours \n\
9 - contact : type de contact (cellular, phone, unknown) \n\
10 - day : le jour du mois o√π le client a √©t√© contact√© \n\
11 - month : le mois o√π le client a √©t√© contact√© \n\
12 - duration : le temps en ligne avec le client \n\
13 - campaign : combien de fois le client a √©t√© contact√© \n\
                au cours de cette campagne \n\
14 - pdays : combien de jours se sont √©coul√©s depuis le \n\
             dernier contact \n\
15 - previous : combien de fois le client a √©t√© contact√© \n\
                au cours de la pr√©cedente campagne \n\
16 - poutcome : r√©sultat de la pr√©c√©dente campagne \n\
17 - deposit :  r√©sultat de la pr√©sente campagne")

    # deposit
    labels = ['No', 'Yes']
    values = df.deposit.value_counts(normalize=True)

    fig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent',
                             insidetextorientation='radial',
                             pull=[0, 0.1])])
    fig.update_layout(title_text="Distribution de la variable cible 'deposit'",
                 margin=dict(t=80, b=10, l=10, r=10))
    fig.update_traces(marker=dict(colors=['lightcoral', 'seagreen'], line=dict(color='#000000', width=1)))

    st.plotly_chart(fig)

    st.write("48% des sond√©s ont r√©pondus √† l'offre positivement")

    # age
    fig = go.Figure()

    fig.add_trace(go.Histogram(x = df['age'][df['deposit'] == 'no'],
                          name = 'no',  
                          marker_color = 'lightcoral'))
    
    fig.add_trace(go.Histogram(x = df['age'][df['deposit'] == 'yes'],
                          name = 'yes',  
                          marker_color = 'seagreen'))

    fig.update_layout(title = 'Distribution de la variable age',
                 xaxis_title = 'age',
                  yaxis_title = 'Count',
                 autosize = False,
                 width = 800, 
                 height = 600,
                 template='simple_white')

    st.plotly_chart(fig)

    st.write("Entre 30 et 60 ans, les clients d√©clinent l'offre plus souvent")

    # balance
    fig = go.Figure()
    dfq = df.copy()
    dfq['balance'] = pd.qcut(dfq.balance, [0, .25, .5, .75, .9, 1.]).astype('str')
    fig.add_trace(go.Histogram(x = dfq['balance'][dfq['deposit'] == 'yes'],
                          name = 'yes', # Label 
                          marker_color = 'seagreen',
                          histnorm='percent',
                          opacity=0.8)) # Couleur des barres 

    fig.add_trace(go.Histogram(x = dfq['balance'][dfq['deposit'] == 'no'],
                          name = 'no', # Label 
                          marker_color = 'lightcoral',
                          histnorm='percent',
                          opacity=0.8)) # Couleur des barres 

    fig.update_layout(title = 'Distribution de la variable balance',
                 xaxis_title = 'balance',
                 yaxis_title = 'frequency',
                 width = 800, 
                 height = 600,
                 template='simple_white')

    st.plotly_chart(fig)

    st.write("Sans surprise, les clients ayant peu d'argent sur leur compte r√©pondent \
en moyenne n√©gativement √† l'offre. Il serait donc pr√©f√©rable de contacter les clients \
avec une somme minimal sur leur compte bancaire.")

    # day
    fig = go.Figure()

    fig.add_trace(go.Histogram(x = df['day'][df['deposit'] == 'yes'],
                          name = 'yes',  
                          marker_color = 'seagreen'))

    fig.add_trace(go.Histogram(x = df['day'][df['deposit'] == 'no'],
                          name = 'no',  
                          marker_color = 'lightcoral'))

    fig.update_layout(title = 'Distribution de la variable day',
                 xaxis_title = 'day',
                  yaxis_title = 'Count',
                 autosize = False,
                 width = 800, 
                 height = 600,
                 template='simple_white')

    st.plotly_chart(fig)    

    st.write("La variable 'day' repr√©sente le jour du mois o√π le client a √©t√© appel√©. On observe qu'en moyenne \
si les clients ont √©t√© appel√© dans les deux derni√®res semaines du mois, ils seront plus suceptible \
de r√©pondre n√©gativement √† l'offre.")

    # month
    fig = go.Figure()

    fig.add_trace(go.Histogram(x = df['month'][df['deposit'] == 'yes'],
                            name = 'yes',  
                            marker_color = 'seagreen'))

    fig.add_trace(go.Histogram(x = df['month'][df['deposit'] == 'no'],
                            name = 'no',  
                            marker_color = 'lightcoral'))

    fig.update_layout(title = 'Distribution de la variable month',
                    xaxis_title = 'month',
                    yaxis_title = 'Count',
                    autosize = False,
                    width = 800, 
                    height = 600,
                    template='simple_white')

    st.plotly_chart(fig)

    st.write("On voit nettement que certains moins, les clients seront moins r√©ceptifs \
√† l'offre promotionnelle. En mai, seule 1 personne sur 3 √† effectuer un d√©p√¥t √† terme.")

    # education
    fig = go.Figure()

    fig.add_trace(go.Histogram(x = df['education'][df['deposit'] == 'yes'],
                            name = 'yes',  
                            marker_color = 'seagreen'))

    fig.add_trace(go.Histogram(x = df['education'][df['deposit'] == 'no'],
                            name = 'no',  
                            marker_color = 'lightcoral'))

    fig.update_layout(title = 'Distribution de la variable education',
                    xaxis_title = 'education',
                    yaxis_title = 'Count',
                    autosize = False,
                    width = 800, 
                    height = 600,
                    template='simple_white')

    st.plotly_chart(fig)

    st.write("Ici, on peut dire que les personnes ayant fait des √©tudes sup√©rieurs ont plus tendance \
√† accepter l'offre que s'ils s'√©taient arr√™t√©s au secondaire ou en primaire.")

    # marital
    fig = go.Figure()

    fig.add_trace(go.Histogram(x = df['marital'][df['deposit'] == 'yes'],
                            name = 'yes',  
                            marker_color = 'seagreen'))

    fig.add_trace(go.Histogram(x = df['marital'][df['deposit'] == 'no'],
                            name = 'no',  
                            marker_color = 'lightcoral'))

    fig.update_layout(title = 'Distribution de la variable marital',
                    xaxis_title = 'marital',
                    yaxis_title = 'Count',
                    autosize = False,
                    width = 800, 
                    height = 600,
                    template='simple_white')

    st.plotly_chart(fig)

    # job
    fig = go.Figure()

    fig.add_trace(go.Histogram(x = df['job'][df['deposit'] == 'yes'],
                            name = 'yes',  
                            marker_color = 'seagreen'))

    fig.add_trace(go.Histogram(x = df['job'][df['deposit'] == 'no'],
                            name = 'no',  
                            marker_color = 'lightcoral'))

    fig.update_layout(title = 'Distribution de la variable job',
                    xaxis_title = 'job',
                    yaxis_title = 'Count',
                    autosize = False,
                    width = 800, 
                    height = 600,
                    template='simple_white')

    st.plotly_chart(fig)

    st.write("Certains m√©tiers affichent des tendances nettes : les cols bleus ne sont pas \
        √† prioriser lors de contacts par la banque car peu int√™ress√©s par l'offre. Au contraire \
        les retrait√©s ou les √©tudiants sont des clients prioritaires.")

    # poutcome
    fig = px.parallel_categories(df, dimensions=['poutcome', 'deposit'],
                             color_continuous_scale=px.colors.sequential.Inferno)

    st.plotly_chart(fig)

    st.write("La variable 'poutcome' a 4 modalit√©s, dont une se nomme 'unknown', soit une valeur \
     inconnu, cependant cette variable nous donne des informations importantes sur les r√©sultats \
         de l'enqu√™te. Essayons d'en savoir plus")
    
    st.code("df.poutcome[df.previous == 0].unique() --> unknown")
        
    st.write("En effet, la variable 'previous' nous indique si la personne a d√©j√† √©t√© contact√© avant \
         cette campagne et si oui, combien de fois. \
             Apr√®s filtrage du dataframe pour les personne n'ayant jamais √©t√© contact√©, la modalit√© 'unknown' est affich√©e, ce qui indique \
             que ce sont des personnes qui sont contact√© pour la 1√®re fois")

###### page tests statistiques ######

elif page == "Tests statistiques":
    #pearson
    st.markdown('**La matrice de corr√©lation (test de Pearson) :**')

    fig, ax = plt.subplots(figsize=(10,8))
    sns.heatmap(df.corr(), annot=True,cmap='viridis')
    plt.title('Coefficient de Pearson')
    st.pyplot(fig)


    st.write('Le tableau affich√© nous donne les informations suivantes : statistique du test, p-value, \
degr√© de libert√©, V de Cramer (coefficient de corr√©lation du ùúí2)')

    st.latex(r'''test  du  \chi 2''')
    from scipy.stats import chi2_contingency
    df_cat = df.select_dtypes('object')
    def V_Cramer(table, N):
        stat_chi2 = chi2_contingency(table)[0]
        k = table.shape[0]
        r = table.shape[1]
        phi_2 = max(0,(stat_chi2)/N - ((k - 1)*(r - 1)/(N - 1)))
        k_b = k - (np.square(k - 1) / (N - 1))
        r_b = r - (np.square(r - 1) / (N - 1))   
        return np.sqrt(phi_2 / min(k_b - 1, r_b - 1))

    dico = {}
    for col in df_cat.columns[df_cat.columns != 'deposit']:
        table = pd.crosstab(df_cat[col], df['deposit'])
        res = chi2_contingency(table)
        dico[col] = [res[0], res[1], res[2], V_Cramer(table, df.shape[0])]
    
    
    stats = pd.DataFrame.from_dict(dico).transpose()
    stats = stats.rename(columns={0:'chi 2', 1:'p-value', 2:'DoF', 3:'V de Cramer'})
    st.write(stats)
    st.write("Ce test nous donne des informations sur la corr√©lation entre les variables cat√©gorielles et la variable cible. \
16 Les variables ayant un V de Cramer compris entre 20 et 30 sont des variables tr√®s corr√©l√©es √† la variable \
deposit, on a entre autres: - housing, contact, month, poutcome.")

    st.markdown('**test ANOVA**')
    st.write('Il est aussi possible de faire un test ANOVA entre les variables quantitatives et les \
variables qualitatives. ANOVA (ANalyse Of VAriance), compare l‚Äô√©cart des moyennes \
d‚Äô√©chantillons par rapport √† la moyenne globale. Plus l‚Äô√©cart est important plus la \
variance est grande, et inversement. Le test renvoie la statistique F et la p-value, qui va \
nous servir √† rejeter ou non l‚Äôhypoth√®se. En g√©n√©ral, plus F est √©lev√©, moins les \
variables sont corr√©l√©es, elles sont donc chacunes pertinentes.')
    import statsmodels.api
    result = statsmodels.formula.api.ols('balance ~ loan', data=df).fit()
    table = statsmodels.api.stats.anova_lm(result)
    st.write(table)
    st.write("Ici, on voit que la variable balance et la variable loan obtiennent une p-value tr√®s faible, \
on peut donc rejeter l‚Äôhypoth√®se H0 entre ces 2 variables.")

###### page machine learning ######

elif page == "Machine learning":
    st.write('Essayons dans cette partie, de transformer les donn√©es afin que le mod√®le les exploitent \
au mieux. Concentrons nous sur la r√©partition des 2 variables quantitatives ‚Äì previous et \
campaign ‚Äì suivantes, affich√©es √† l‚Äôaide d‚Äôun boxplot :')
    st.write('boxplot "previous"')

    fig, ax = plt.subplots(figsize=(20,6))
    sns.boxplot(df.previous)
    st.pyplot(fig)
    st.write('boxplot "campaign"')
    fig, ax = plt.subplots(figsize=(20,6))
    sns.boxplot(df.campaign)
    st.pyplot(fig)

    st.write('On remarque certaines valeurs extr√™mes. On peut s‚Äôy int√©resser en affichant les lignes dans \
    le dataframe li√©es √† ces valeurs.')
    st.write('Quand previous > 35')
    st.write(df[df['previous']>35])
    st.write('Pour rappel, previous nous indique le nombre de fois que le client a √©t√© appel√©, avant cette \
campagne. 2 clients sur 5 ont r√©pondu positivement √† l‚Äôoffre.')
    st.write('Quand campaign > 35')
    st.write(df[df['campaign']>35])

    st.write("Pour ces clients, aucun n'a r√©pondu positivement √† la campagne. \
Ces valeurs ne repr√©sentent pas la majorit√© des clients, il serait utile de majorer la variable \
campaign, pour le faire, on remplacera les valeurs extr√™mes par la moyenne de la variable. \
On garde les valeurs extr√™mes de previous car certains ont r√©pondus positivement, c‚Äôest \
donc des informations utiles pour savoir quel type de client est susceptible de faire un \
d√©p√¥t apr√®s la campagne. Par la m√™me occasion, on va cr√©er une copie de df pour nos \
prochaines transformations, et aussi, binaris√© la variable deposit.")


    st.markdown('**Il vient ensuite le feature engeneering des variables :**')

    st.write('On remplace les variables binaires par 0 ou 1')
    st.write('On cr√©e des variables indicatrices √† partir des variables cat√©gorielles')
    st.write('On supprimes les variables dont on a plus besoin')
    st.write(data.head())

    st.write("On peut dor√©navant appliquer nos mod√®les de classification sur nos donn√©es. Avant cela, \
on va diviser notre jeu de donn√©es en un set d'entra√Ænement et un set de test, pour pouvoir \
ensuite v√©rifier la pr√©cision de nos mod√®les via plusieurs m√©triques. \
Essayons plusieurs mod√®les pour voir les plus performants.")

    model = st.selectbox(label="Choix du mod√®le", options=["Gradient Boosting", "Decision Tree",
     'Random Forest Classifier', 'Logistic Regression'])

    def get_model(model):
        if model == "Gradient Boosting":
            model = GradientBoostingClassifier(n_estimators = 200,
                                  learning_rate=0.1,
                                  max_depth = 6,
                                  random_state = 234)
        elif model == "Decision Tree":
            model = DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=234)
        elif model == 'Random Forest Classifier':
            model = RandomForestClassifier()
        elif model == 'Logistic Regression':
            model = LogisticRegression()

        model.fit(X_train, y_train)
        score = model.score(X_test,y_test)

        return score

    st.write("Score test :", get_model(model))

    # cross validation
    st.markdown('**Validation crois√©e**')
    gbc_score = cross_val_score(gbc, X=X_train, y=y_train, cv=5, scoring='accuracy', n_jobs=-1)
    dt_score = cross_val_score(dt, X=X_train, y=y_train, cv=5, scoring='accuracy', n_jobs=-1) 
    st.write('Cross validation score GradientBoosting :', gbc_score.mean(), '%')  
    st.write('Cross validation score DecisionTree :', dt_score.mean(), '%') 


    # feature importance
    st.markdown("L'importance des variables d√©termin√©es par les mod√®les :")

    feature = {}
    for feat, imp in zip(data.columns, dt.feature_importances_):
        feature[feat] = imp
    
    tab = pd.DataFrame.from_dict(feature, orient='index', columns=['importance'])
    tab = tab.sort_values(by='importance', ascending=False)

    fig, ax = plt.subplots(figsize=(10,6))
    x = np.arange(0, 10)
    sns.barplot(tab['importance'].head(10), x, orient='h')
    plt.yticks(x, tab.index[0:10])
    plt.title('Feature importances (DecisionTree)')
    st.pyplot(fig)

    feature = {}
    for feat, imp in zip(data.columns, gbc.feature_importances_):
        feature[feat] = imp
    
    tab = pd.DataFrame.from_dict(feature, orient='index', columns=['importance'])
    tab = tab.sort_values(by='importance', ascending=False)

    fig, ax = plt.subplots(figsize=(10,6))
    x = np.arange(0, 10)
    sns.barplot(tab['importance'].head(10), x, orient='h')
    plt.yticks(x, tab.index[0:10])
    plt.title('Feature importances (Gradient Boosting)')
    st.pyplot(fig)

    st.write("Les 3 variables les plus importantes en termes d‚Äôinformations pertinentes est poutcome=\
success, contact=unknown et age pour le mod√®le d‚Äôarbre de d√©cision. \
Pour le mod√®le de gradient boosting, on a : balance, poutcome (success) et age. \
Les variables age et poutcome sont donc des informations √† privil√©gier lors d‚Äôune \
campagne, notamment le fait que les clients contact√©s qui ont r√©pondu positivement √† une \
pr√©c√©dente campagne, ont plus de chance de r√©pondre positivement √† une autre \
campagne. Ils seront donc √† contacter en priorit√© pour de futures campagnes. On peut \
aussi s‚Äôen assurer visuellement :")


    fig, ax = plt.subplots(figsize=(10,6))
    sns.countplot(df['poutcome'][df['poutcome']=='success'], hue=df.deposit)
    st.pyplot(fig)

    st.write('En effet, les clients ayant d√©j√† profiter d‚Äôune offre ant√©rieure, ont r√©pondu en grande \
majorit√© positivement √† la campagne √©tudi√©e.')

    st.markdown('**Arbre de d√©cision :**')
    from sklearn import tree
    dt = DecisionTreeClassifier(max_depth=6)
    dt.fit(X_train, y_train)
    st.write('score decision tree')
    st.write(dt.score(X_test, y_test))
    fig, ax = plt.subplots(figsize=(20,8))
    tree.plot_tree(dt, max_depth=2, filled=True, feature_names=X_train.columns, class_names=True)
    st.pyplot(fig)
    
    y_pred = gbc.predict(X_test)
    st.write("On y voit les n≈ìuds de d√©cision, qui se splitent pour effectuer la classification selon un \n\
certain seuil par variable. Lorsque le n≈ìud ne se split plus, on parle alors de leaf (feuille). On peut \n\
modifier ces param√®tres afin de contr√¥ler pour en optimiser son efficacit√© de classification : par exemple, \n\
un nombre de noeuds trop important am√®nerait √† du surapprentissage.")
    st.write("On peut afficher une matrice de confusion pour s'aider dans la compr√©hension du mod√®le:")
    st.image("https://user-images.githubusercontent.com/62601686/165782931-eb29223f-6570-4b84-850e-477fae038118.png", width=600)
    st.write("Plusieurs crit√®res de performances d√©coulent de la matrice de confusion, ainsi on a :\n\
1 - **Le Rappel** (recall) : mesure le taux de vrais positifs, d√©fini par : ")
    st.latex(r'''Rappel = \frac{TP}{TP + FN}''')
    st.write("C'est la capacit√© de notre mod√®le √† bien idientifier les clients ayant souscris √† l'offre ainsi que les \n\
faux n√©gatifs, soit les personnes qu'on pense avoir fait un d√©p√¥t √† terme mais qui n'ont pas souscris √† l'offre.")
    st.write("2 - **La Pr√©cision** : mesure la performance du mod√®le √† d√©tecter les clients qui vont faire \n\
un d√©p√¥t √† terme. On a des informations sur les faux positifs aussi, c'est-√†-dire ceux qui vont faire un \n\
d√©p√¥t d'argent mais qui ne seront pas d√©tecter. Donc cela permet de limiter les actions envers ces clients \n\
car ils ne font pas partie des personnes sceptiques √† l'offre et donc sur qui il faudrait d√©ployer d'autres \n\
ressources.")
    st.latex(r'''Precision = \frac{TP}{TP + FP}''')
    st.code(pd.crosstab(y_test, y_pred, rownames=['Classe pr√©dite'], colnames=['Classe r√©elle']))
    st.write("Le rapport de classification condense ces informations, on a en plus le F-1 score, une \n\
m√©trique qui combine le rappel et la pr√©cision :")
    st.code(metrics.classification_report(y_test, y_pred))
    prec = round(metrics.precision_score(y_test, y_pred),2)*100
    rec = round(metrics.recall_score(y_test, y_pred),2)*100
    

    st.markdown('**Courbe ROC :**')
    st.write('Tra√ßons maintenant la courbe ROC. La courbe ROC affiche la ‚Äúsensibilit√©‚Äù (Vrai positif) en \n\
fonction de ‚Äúantisp√©cificit√©‚Äù (Faux positif). On calcul en fait l‚Äôair sous la courbe (AUC, area under the curve). \n\
Si cette valeur est de 0,5 (50%), le mod√®le est al√©atoire, plus l‚Äôaire est importante, plus notre mod√®le sera \n\
performant et arrivera √† classifier correctement.')


    from sklearn.metrics import roc_curve
    from sklearn.metrics import auc

    fig, ax = plt.subplots(figsize=(10,8))

    y_pred = dt.predict(X_test)
    probs = dt.predict_proba(X_test)
    fpr, tpr, seuils = roc_curve(y_test, probs[:,1], pos_label=1)
    plt.plot(fpr, tpr, color='red', lw=3, label='Mod√®le DT (auc = {}%)'.format(auc(fpr, tpr).round(2)*100))

    y_pred = gbc.predict(X_test)
    probs = gbc.predict_proba(X_test)
    fpr, tpr, seuils = roc_curve(y_test, probs[:,1], pos_label=1)
    plt.plot(fpr, tpr, color='orange', lw=3, label='Mod√®le GB (auc = {}%)'.format(auc(fpr, tpr).round(2)*100))

    x = np.linspace(0,1,50)
    plt.plot(x, x, 'b--', lw=3, label='Al√©atoire (auc = 0.5)')
    plt.xlim(0,1.02)
    plt.ylim(0,1.02)
    plt.legend(loc='lower right')
    plt.xlabel('Taux faux positifs')
    plt.ylabel('Taux vrais positifs')
    plt.title('Courbe ROC')
    plt.grid(False)
    st.pyplot(fig)

    st.markdown('**GridSearchCV :**')


    from sklearn.model_selection import GridSearchCV

    with st.echo():
        hyperparameter = dict(max_depth = [5, 15], min_samples_leaf = [3, 10])

        gridP = GridSearchCV(gbc, hyperparameter, cv = 3, verbose = 1, n_jobs = -1)
        grille = gridP.fit(X_train, y_train)

    st.write('meilleurs param√®tres selectionn√©s :')
    st.code(gridP.best_params_)
    y_pred = gridP.predict(X_test)
    st.write('gradient boosting accuracy test score with best param : ')
    st.code(metrics.accuracy_score(y_test, y_pred).round(2))
